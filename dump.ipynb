{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fade_in(alpha, a, b):\n",
    "    '''\n",
    "    Smoothing function\n",
    "    '''\n",
    "    return alpha * a + (1- alpha ) * b\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Wasserstein Loss ( Refer to WGANs)\n",
    "    '''\n",
    "    return - (y_true * y_pred).mean()\n",
    "\n",
    "def pixel_norm(x, epsilon = 1e-8):\n",
    "    return x / torch.sqrt(torch.mean(x**2, dim = -1, keepdim=True)+ epsilon)\n",
    "\n",
    "def minibatch_std(tensor_input : torch.Tensor, epsilon = 1e-8):\n",
    "    '''\n",
    "    Minibatch Standard Deviation (ref : <https://arxiv.org/pdf/1710.10196.pdf>)\n",
    "    '''\n",
    "    n, c, h, w,  = tensor_input.shape\n",
    "\n",
    "    # shape into minibatches of size 4\n",
    "    group_size = min(4,n)\n",
    "    x = torch.reshape(tensor_input,[group_size,-1, c, h, w]).float()\n",
    "    num_batches = x.shape[1]\n",
    "\n",
    "    # calculate group standard deviation\n",
    "    group_var = x.var(0,unbiased=False)\n",
    "    group_std = torch.sqrt(group_var+epsilon)\n",
    "\n",
    "\n",
    "    # average deviation per minibatch\n",
    "    avg_std = torch.mean(group_std, dim=[1,2,3], keepdim=True)\n",
    "    avg_std = avg_std.repeat(group_size,num_batches,1,h,w)\n",
    "\n",
    "\n",
    "    # adding channel with mean of std of mini-batches\n",
    "    return torch.cat([x,avg_std],dim=2).reshape(n,c+1,h,w)\n",
    "\n",
    "\n",
    "\n",
    "class EqualizedConv2D(nn.Module):\n",
    "    def __init__(self, out_channels=1, kernel = 3, gain = 2, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.initialized = False\n",
    "        self.kernel = kernel\n",
    "        self.out_channels = out_channels\n",
    "        self.gain = gain\n",
    "\n",
    "        self.register_parameter('weights',None)\n",
    "        self.register_parameter('bias',None)\n",
    "\n",
    "    \n",
    "    def build(self, input : torch.Tensor):\n",
    "        self.in_channels = input.shape[1]\n",
    "\n",
    "        self.weights = nn.Parameter(input.new(self.out_channels, self.in_channels,self.kernel,self.kernel).normal_())\n",
    "        self.bias = nn.Parameter(input.new(self.out_channels).zero_())\n",
    "\n",
    "        fan_in = self.kernel * self.kernel * self.in_channels\n",
    "        self.scale = math.sqrt(self.gain / fan_in)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        if not self.initialized:\n",
    "            self.build(X)\n",
    "            self.initialized = True\n",
    "        return F.conv2d(X, self.weights, self.bias, padding='same')\n",
    "\n",
    "class EqualizedDense(nn.Module):\n",
    "    def __init__(self, dim_out, gain = 2, lr_multiplier = 1.0, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.initialized = False\n",
    "        self.dim_out = dim_out\n",
    "        self.gain = gain\n",
    "        self.lr_multiplier = lr_multiplier\n",
    "\n",
    "        self.register_parameter('weights',None)\n",
    "        self.register_parameter('bias',None)\n",
    "\n",
    "    def build(self, input : torch.Tensor):\n",
    "        self.dim_in = input.shape[-1]\n",
    "\n",
    "        self.weights = nn.Parameter(input.new(self.dim_out, self.dim_in).normal_(0.0,1.0/ self.lr_multiplier))\n",
    "        self.bias = nn.Parameter(input.new(self.dim_out).zero_())\n",
    "        \n",
    "        self.scale = math.sqrt(self.gain / self.dim_in)\n",
    "\n",
    "    def forward(self, X):\n",
    "        print(self.initialized)\n",
    "        if not self.initialized:\n",
    "            self.build(X)\n",
    "            self.initialized = True\n",
    "        \n",
    "        return F.linear(X, self.scale * self.weights, self.bias) * self.lr_multiplier\n",
    "    \n",
    "class AddNoise(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.initialized = False\n",
    "        self.register_parameter('bias',None)\n",
    "\n",
    "    def build(self, input : torch.Tensor):\n",
    "        n, c, h, w = input.shape[0]\n",
    "\n",
    "        self.bias = nn.Parameter(input.new(1,c,1,1).normal_())\n",
    "    \n",
    "    def forward(self, X):\n",
    "        if not self.initialized:\n",
    "            self.build(X)\n",
    "            self.initialized = True\n",
    "        \n",
    "        x, noise = X\n",
    "        return x + self.bias * noise\n",
    "\n",
    "class AdaIN(nn.Module):\n",
    "    def __init__(self, gain =1 , **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.gain = gain\n",
    "        self.initialized = False\n",
    "\n",
    "        self.register_module(\"dense_1\",None)\n",
    "        self.register_module(\"dense_2\",None)\n",
    "    \n",
    "    def build(self, input):\n",
    "        x, w = input\n",
    "\n",
    "        x_shape = x.shape\n",
    "        w_shape = w.shape\n",
    "\n",
    "        self.w_channels = w_shape[1]\n",
    "        self.x_channels = x_shape[1]\n",
    "\n",
    "        self.dense_1 = EqualizedDense(self.x_channels, gain =1 )\n",
    "        self.dense_2 = EqualizedDense(self.x_channels, gain =1 )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        if not self.initialized:\n",
    "            self.build(X)\n",
    "            self.initialized = True\n",
    "        x, w = X\n",
    "        ys = self.dense_1(w).reshape([-1,self.x_channels,1,1])\n",
    "        yb = self.dense_2(w).reshape([-1,self.x_channels,1,1])\n",
    "\n",
    "        return ys *x + yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapping(nn.Module):\n",
    "    def __init__(self, num_stages, input_shape = 512) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_stages = num_stages\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        layers =  []\n",
    "\n",
    "        for i in range(8):\n",
    "            layers.append(EqualizedDense(input_shape, 512,1, lr_multiplier=0.01))\n",
    "            layers.append(nn.LeakyReLU())\n",
    "        \n",
    "        self.layers  = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        x = self.layers(X)\n",
    "        return torch.tile(x.unsqueeze(1),(1,self.num_stages,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.9273, 0.9273, 0.9273, 0.9273, 0.9273],\n",
       "          [0.9273, 0.9273, 0.9273, 0.9273, 0.9273]],\n",
       "\n",
       "         [[1.8117, 1.8117, 1.8117, 1.8117, 1.8117],\n",
       "          [1.8117, 1.8117, 1.8117, 1.8117, 1.8117]]],\n",
       "\n",
       "\n",
       "        [[[0.9273, 0.9273, 0.9273, 0.9273, 0.9273],\n",
       "          [0.9273, 0.9273, 0.9273, 0.9273, 0.9273]],\n",
       "\n",
       "         [[1.8117, 1.8117, 1.8117, 1.8117, 1.8117],\n",
       "          [1.8117, 1.8117, 1.8117, 1.8117, 1.8117]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = AdaIN()\n",
    "\n",
    "A(torch.ones(20).view(2,1,2,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_filepath(x:str):\n",
    "    x = x.replace(\".png\",\".jpg\")\n",
    "    x = x.split(\"/\")\n",
    "    x.pop(1)\n",
    "    return \"/\".join(x)\n",
    "\n",
    "def load_information(x):\n",
    "    json_name = x['image']['file_path'].split(\"/\")[-1].split(\".\")[0]+\".json\"\n",
    "    json_path = os.path.join(\"./ffhq-features-dataset/json/\",json_name)\n",
    "    props = json.load(open(json_path,\"r\"))\n",
    "    if len(props) == 0:\n",
    "        return False\n",
    "    return props[0]['faceAttributes']['glasses'] != 'NoGlasses'\n",
    "    \n",
    "\n",
    "data = pd.read_json(os.path.join(\"./\",\"ffhq-dataset-v2.json\"),orient=\"index\")\n",
    "data['info'] = data.progress_apply(load_information,axis=1)\n",
    "glasses_data = data[data['info']].copy()\n",
    "glasses_data['image_path'] = glasses_data.apply(lambda x : process_filepath(x['thumbnail']['file_path']),axis=1)\n",
    "glasses_data = glasses_data.drop(columns=['image','thumbnail','in_the_wild','metadata','info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [glasses_data['image_path'].iloc[random.randint(0,glasses_data.shape[0])].split(\"/\")[-1] for _ in range(0,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glasses_data = data[data['info']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glasses_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 10/10 [00:00<00:00, 30863.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://drive.google.com/uc?id=152iXH9YjbbEmttREAcSVb8-TZ7PL8glS\n",
      "https://drive.google.com/uc?id=1Bc_8qQh_s5wRxLX7h3p66DzLOnZM0ZUc\n",
      "https://drive.google.com/uc?id=1sHNJjposMdiVedHl_2gZJCfe35yFt0D8\n",
      "https://drive.google.com/uc?id=1xVnCNWsmFw70GyWvL_ggdjPWFKoViH7X\n",
      "https://drive.google.com/uc?id=16Az_0hEhgDqt883pVwmiqHEapGxPv_bx\n",
      "https://drive.google.com/uc?id=1z-J-1RysweG1aTl2t00SXVq5iUdvtP5G\n",
      "https://drive.google.com/uc?id=1jlfsR81VKF5p2f19H8UCcWCR5DVa1Asu\n",
      "https://drive.google.com/uc?id=1SZ_pt5eFY1p7KdkRBzPEhzXm2Dt1Zzo4\n",
      "https://drive.google.com/uc?id=1YvROueVSJthYxsyVTL8s0phZ2c_WJ9TV\n",
      "https://drive.google.com/uc?id=1BsrKrRglMmwCyNPIB3djYO27HUjqp-SQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "for i in tqdm(range(0,10)):\n",
    "    print(images['image'].iloc[i]['file_url'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
