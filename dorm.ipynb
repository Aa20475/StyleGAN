{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79515b0-13e7-4245-b563-8ebc23e45b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "import dnnlib\n",
    "import torch_utils\n",
    "import pickle\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import stylegan2.training.dorm_networks as networks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import tqdm as T\n",
    "import random\n",
    "tqdm.pandas()\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10730261-6e6c-4196-9723-a8747c02fac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stylegan = pickle.load(open(\"./pretrained_stylegans/ffhq.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3ff92ee-6068-4ba9-9b7a-ab5628ad0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21b1181f-e415-4898-8f32-188e91f38295",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = stylegan['G']\n",
    "G = networks.DoRMGenerator(generator.z_dim,generator.c_dim,generator.w_dim,generator.img_resolution,generator.img_channels).to(device) \n",
    "_ = G.load_state_dict(generator.state_dict(),strict = False)\n",
    "D = stylegan['D'].to(device)\n",
    "\n",
    "del generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53681ec0-ee1d-453d-b08f-1511c0840a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.requires_grad_(False)\n",
    "G.target_mapping.requires_grad_(True)\n",
    "for x, i in G.named_modules():\n",
    "    if 'target_affine' in x:\n",
    "        i.requires_grad_(True)\n",
    "\n",
    "D.requires_grad_(False)\n",
    "for i in range(2,6):\n",
    "    getattr(D,f'b{2**i}').requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01157625-0103-439c-85b6-ff8e31114e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "opt_g = optim.Adam([{'params': [param for name, param in G.named_parameters() if 'target_affine' in name]},\n",
    "                     {'params': G.target_mapping.parameters(), 'lr': 1e-5}], lr=LR, betas =(0.0, 0.99))\n",
    "opt_d = optim.Adam(\n",
    "    D.parameters(), lr= LR, betas =(0.0, 0.99)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d3cb75-ec31-4fe8-819e-83f328b8abdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"./DoRM/anime_faces/\"\n",
    "im_names = None\n",
    "for x in os.walk(target_folder):\n",
    "    im_names = x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9243a5ed-1cc5-4fb2-9f01-178afc4dd09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3685403/2328931497.py:13: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  data = torch.Tensor(np.array([trainsform(torch.from_numpy(plt.imread(os.path.join(target_folder,x))).permute(2,0,1)).numpy() for x in im_names])).to(device)\n"
     ]
    }
   ],
   "source": [
    "trainsform = transforms.Compose(\n",
    "    [transforms.ToPILImage(),\n",
    "     transforms.Resize((1024, 1024)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.Normalize(\n",
    "        [0.5 for _ in range(3)],\n",
    "        [0.5 for _ in range(3)],\n",
    "     )\n",
    "    ]\n",
    ")\n",
    "\n",
    "data = torch.Tensor(np.array([trainsform(torch.from_numpy(plt.imread(os.path.join(target_folder,x))).permute(2,0,1)).numpy() for x in im_names])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf00e7-4007-4575-8e67-92f7b284818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–‰                                                                                                                                                                      | 528/100000 [01:46<5:36:23,  4.93it/s]"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "total_samples = 100000\n",
    "with tqdm(total=total_samples) as pbar:\n",
    "    while counter < total_samples:\n",
    "        target_batch = data[[random.randint(0,9) for _ in range(4)]]\n",
    "\n",
    "        zs = torch.randn(4, G.z_dim).to(device)\n",
    "        zt = torch.randn(4, G.z_dim).to(device)\n",
    "        c = torch.zeros(4,G.c_dim).to(device)\n",
    "        \n",
    "        # generate images from both source & target domains\n",
    "        gen_target = G(zs, zt, c, 1.0)\n",
    "        # gen_source = G(zs, zt, c, 0.0)\n",
    "        \n",
    "        disc_target = D(target_batch,c)\n",
    "        disc_gen = D(gen_target,c)\n",
    "        # disc_source = D(gen_source.detach(),c)\n",
    "        \n",
    "        # Critic loss is loss for \n",
    "        loss_disc = -torch.mean(1 - disc_gen) - torch.mean(disc_target)\n",
    "        # loss_disc = -torch.mean(1 - disc_gen) - torch.mean(disc_target) + torch.mean(disc_source)\n",
    "        D.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_d.step()\n",
    "        \n",
    "        gen_target = G(zs, zt, c, 1.0)\n",
    "        disc_gen = D(gen_target,c)\n",
    "        \n",
    "        loss_gen = -torch.mean(disc_gen)\n",
    "        loss_gen.backward()\n",
    "        opt_g.step()\n",
    "\n",
    "        counter+=4\n",
    "        pbar.update(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fcbfa8-7f52-42dc-9966-e4f2050167a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
