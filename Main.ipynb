{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetRoot = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2(x):\n",
    "    return int(math.log2(x))\n",
    "\n",
    "def plot_images(images, log2_res, fname=\"\"):\n",
    "    '''\n",
    "    Helper function to plot a set of images\n",
    "    '''\n",
    "    scales = {2: 0.5, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8}\n",
    "    scale = scales[log2_res]\n",
    "\n",
    "    grid_col = min(images.shape[0], int(32 // scale))\n",
    "    grid_row = 1\n",
    "\n",
    "    f, axarr = plt.subplots(\n",
    "        grid_row, grid_col, figsize=(grid_col * scale, grid_row * scale)\n",
    "    )\n",
    "\n",
    "    for row in range(grid_row):\n",
    "        ax = axarr if grid_row == 1 else axarr[row]\n",
    "        for col in range(grid_col):\n",
    "            ax[col].imshow(images[row * grid_col + col])\n",
    "            ax[col].axis(\"off\")\n",
    "    plt.show()\n",
    "    if fname:\n",
    "        f.savefig(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [00:00<00:00, 170878.14it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_filepath(x):\n",
    "    x = x.split(\"/\")\n",
    "    x.pop(1)\n",
    "    return \"/\".join(x)\n",
    "\n",
    "data = pd.read_json(os.path.join(datasetRoot,\"ffhq-dataset-v2.json\"),orient=\"index\")\n",
    "data['image_path'] = data.progress_apply(lambda x : process_filepath(x['thumbnail']['file_path']),axis=1)\n",
    "data = data.drop(columns=['image','thumbnail','in_the_wild','metadata'])\n",
    "\n",
    "train_data = data.loc[data['category']=='training'].drop(columns=['category'])\n",
    "validation_data = data.loc[data['category']=='validation'].drop(columns=['category']).reset_index().drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFHQDataset(Dataset):\n",
    "    \"\"\" Dataset to load FFHQ data from a dataframe\n",
    "\n",
    "    Args:\n",
    "\n",
    "        dataframe : dataframe with image paths in column 'image_path'\n",
    "        datasetRoot : the root path to join before the image_path, if any.\n",
    "        res : resolution of the image generated\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, datasetRoot, res = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.dataframe = dataframe\n",
    "        self.datasetRoot = datasetRoot\n",
    "        self.res = res\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, index) :\n",
    "        img_path = os.path.join(self.datasetRoot,self.dataframe['image_path'].iloc[index])\n",
    "        image = read_image(img_path)\n",
    "        return Resize((self.res,self.res))(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FFHQDataset(train_data,datasetRoot)\n",
    "validation_dataset = FFHQDataset(validation_data,datasetRoot)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 3, 2, 2])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "img = train_features[0][1]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fade_in(alpha, a, b):\n",
    "    '''\n",
    "    Smoothing function\n",
    "    '''\n",
    "    return alpha * a + (1- alpha ) * b\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    '''\n",
    "    Wasserstein Loss ( Refer to WGANs)\n",
    "    '''\n",
    "    return - (y_true * y_pred).mean()\n",
    "\n",
    "def pixel_norm(x, epsilon = 1e-8):\n",
    "    return x / torch.sqrt(torch.mean(x**2, dim = -1, keepdim=True)+ epsilon)\n",
    "\n",
    "def minibatch_std(x, eps=1e-8):\n",
    "    \"\"\"Compute the mini-batch standard deviation of input tensor x.\n",
    "        ref : <https://arxiv.org/pdf/1710.10196.pdf>\n",
    "    \"\"\"\n",
    "    batch_size, num_channels, height, width = x.size()\n",
    "    if batch_size < 2:\n",
    "        return torch.zeros(1, num_channels, 1, 1).to(x.device)\n",
    "    mean = torch.mean(x, dim=0, keepdim=True)\n",
    "    var = torch.mean(torch.pow(x - mean, 2), dim=0, keepdim=True)\n",
    "    std = torch.sqrt(var + eps)\n",
    "    mean_std = torch.mean(std, dim=(1, 2, 3), keepdim=True)\n",
    "    mean_std = mean_std.expand(batch_size, -1, height, width)\n",
    "    return torch.cat([x, mean_std], dim=1)\n",
    "\n",
    "\n",
    "class EqualisedConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel = 3, gain = 2) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.w = nn.Parameter(torch.empty(out_channels, in_channels ,kernel, kernel).normal_(), requires_grad= True)\n",
    "        self.b = nn.Parameter(torch.empty(out_channels).zero_() , requires_grad= True)\n",
    "\n",
    "        fan_in = kernel * kernel * in_channels\n",
    "        self.scale = math.sqrt(gain / fan_in)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return F.conv2d(inputs, self.scale * self.w, self.b, padding='same' )\n",
    "\n",
    "\n",
    "class EqualisedLinear(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out , gain = 2, lr_multiplier = 1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.w = nn.Parameter(torch.empty(dim_out,dim_in).normal_(0.0, 1.0 / lr_multiplier), requires_grad= True)\n",
    "        self.b = nn.Parameter(torch.empty(dim_out).zero_(),requires_grad=True)\n",
    "\n",
    "        self.scale = math.sqrt(gain / dim_in)\n",
    "        self.lr_multiplier = lr_multiplier\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return F.linear(inputs, self.scale * self.w, self.b) * self.lr_multiplier\n",
    "\n",
    "class AddNoise(nn.Module):\n",
    "    def __init__(self, x_shape) -> None:\n",
    "        super().__init__()\n",
    "        c , h, w = x_shape\n",
    "        self.b = nn.Parameter(torch.empty([1,c,1,1]).normal_(),requires_grad=True)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x, noise = inputs\n",
    "        return  x + self.b * noise\n",
    "\n",
    "class AdaIn(nn.Module):\n",
    "    def __init__(self, w_channels, x_channels, gain =1) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.x_channels = x_channels\n",
    "\n",
    "        self.dense_1 = EqualisedLinear(w_channels, x_channels, gain)\n",
    "        self.dense_2 = EqualisedLinear(x_channels, x_channels, gain)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x, w = inputs\n",
    "        ys = self.dense_1(w).reshape((-1,self.x_channels,1,1))\n",
    "        yb = self.dense_2(w).reshape((-1,self.x_channels,1,1))\n",
    "\n",
    "        return ys * x + yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorBlock(nn.Module):\n",
    "    def __init__(self, filter_num, res, input_shape, is_base) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.is_base = is_base\n",
    "\n",
    "        # Needs AdaIn & AddNoise Layers\n",
    "        if not is_base:\n",
    "            self.up_sample = nn.Upsample(scale_factor=2)\n",
    "            self.init_conv = EqualisedConv2D(input_shape[0], filter_num, 3)\n",
    "\n",
    "        self.lrelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.add_noise_1 = AddNoise(input_shape)\n",
    "        self.instance_norm_1 = nn.InstanceNorm2d(input_shape[0])\n",
    "        self.ada_in_1 = AdaIn(512, input_shape[0])\n",
    "        self.conv_1 = EqualisedConv2D(input_shape[0], filter_num, 3)\n",
    "\n",
    "        self.add_noise_2 = AddNoise(input_shape)\n",
    "        self.instance_norm_2 = nn.InstanceNorm2d(input_shape[0])\n",
    "        self.ada_in_2 = AdaIn(512, input_shape[0])\n",
    "        self.conv_2 = EqualisedConv2D(input_shape[0], filter_num, 3)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, w, noise = inputs\n",
    "\n",
    "        if not self.is_base:\n",
    "            x = self.up_sample(x)\n",
    "            x = self.init_conv(x)\n",
    "\n",
    "        x = self.add_noise_1([x, noise])\n",
    "        x = self.instance_norm_1(x)\n",
    "        x = self.ada_in_1([x,w])\n",
    "        x = self.conv_1(x)\n",
    "\n",
    "        x = self.add_noise_2([x, noise])\n",
    "        x = self.instance_norm_2(x)\n",
    "        x = self.ada_in_2([x,w])\n",
    "        x = self.conv_2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "#### TEST Generate BLOCK ####\n",
    "# x = GeneratorBlock(512,4,[512,2,2],True)([torch.ones(24,512,2,2),torch.ones(24,512),torch.ones(1,2,2)])\n",
    "# x = EqualisedConv2D(512,3,1,gain = 1)(x)\n",
    "# x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(nn.Module):\n",
    "    def __init__(self, filter_num_1, filter_num_2, res, is_base = False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.is_base = is_base\n",
    "        self.leakyRelu = nn.LeakyReLU(0.2)\n",
    "\n",
    "\n",
    "        if not is_base:\n",
    "            self.conv_1 = EqualisedConv2D(filter_num_1,filter_num_1,3)\n",
    "            self.conv_2 = EqualisedConv2D(filter_num_1,filter_num_2)\n",
    "            self.avg_pool = nn.AvgPool2d((2,2))\n",
    "        else:\n",
    "            self.conv_1 = EqualisedConv2D(filter_num_1+1,filter_num_1,3)\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.lin_1 = EqualisedLinear(res*res*filter_num_1,filter_num_1)\n",
    "            self.lin_2 = EqualisedLinear(filter_num_1,1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # if not base, we don't flatten\n",
    "        if not self.is_base:\n",
    "            x = self.conv_1(inputs)\n",
    "            x = self.leakyRelu(x)\n",
    "            x = self.conv_2(x)\n",
    "            x = self.leakyRelu(x)\n",
    "            x = self.avg_pool(x)\n",
    "            return x\n",
    "        else:\n",
    "        # if base, we flatten & pass through dense\n",
    "            x = minibatch_std(inputs)\n",
    "            x = self.conv_1(x)\n",
    "            x = self.leakyRelu(x)\n",
    "            x = self.flatten(x)\n",
    "            x = self.lin_1(x)\n",
    "            x = self.leakyRelu(x)\n",
    "            x = self.lin_2(x)\n",
    "            return x\n",
    "        \n",
    "#### TEST Dicriminator BLOCK ####\n",
    "# DiscriminatorBlock(5,5,4,False)(torch.ones(24,5,4,4)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"\n",
    "    Generator Module for the StyleGAN Generator\n",
    "    \"\"\"\n",
    "    def __init__(self, start_res_log2, target_res_log2) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.start_res_log2 = start_res_log2\n",
    "        self.target_res_log2 = target_res_log2\n",
    "        self.num_stages = target_res_log2 - start_res_log2 +1\n",
    "\n",
    "        self.curr_res_log2 = start_res_log2\n",
    "\n",
    "        # generator Blocks\n",
    "        self.g_blocks = []\n",
    "        # one rgb block per genblock\n",
    "        self.to_rgb = []\n",
    "\n",
    "        self.filter_nums = {\n",
    "            0: 512,\n",
    "            1: 512,\n",
    "            2: 512,  # 4x4\n",
    "            3: 512,  # 8x8\n",
    "            4: 512,  # 16x16\n",
    "            5: 512,  # 32x32\n",
    "            6: 256,  # 64x64\n",
    "            7: 128,  # 128x128\n",
    "            8: 64,  # 256x256\n",
    "            9: 32,  # 512x512\n",
    "            10: 16,\n",
    "        }\n",
    "\n",
    "        start_res = 2 ** start_res_log2\n",
    "        self.input_shape = (self.filter_nums[start_res_log2], start_res, start_res)\n",
    "        \n",
    "        for i in range(start_res_log2, target_res_log2 + 1):\n",
    "            filter_num = self.filter_nums[i]\n",
    "            res = 2 ** i\n",
    "            \n",
    "            to_rgb = EqualisedConv2D(filter_num , 3, 1, gain=1)\n",
    "\n",
    "            self.to_rgb.append(to_rgb)\n",
    "\n",
    "            is_base = i == self.start_res_log2\n",
    "\n",
    "            if is_base:\n",
    "                input_shape = (self.filter_nums[i - 1], res, res)\n",
    "            else:\n",
    "                input_shape = (self.filter_nums[i - 1], 2 ** (i - 1), 2 ** (i - 1))\n",
    "            \n",
    "            g_block = GeneratorBlock(filter_num, res, input_shape, is_base)\n",
    "            self.g_blocks.append(g_block)\n",
    "\n",
    "        self.up_sample = nn.Upsample(scale_factor=2)\n",
    "        self.g_blocks = nn.ModuleList(self.g_blocks)\n",
    "        self.to_rgb = nn.ModuleList(self.to_rgb)\n",
    "    \n",
    "    def grow(self, res_log2):\n",
    "        self.curr_res_log2 = res_log2\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        g_input, w, noise_inputs, alpha = inputs\n",
    "\n",
    "        \"\"\"\n",
    "        Shapes: \n",
    "            g_input -> self.filter_nums[start_res_log2], start_res, start_res\n",
    "            w -> self.num_stages, 512\n",
    "            noise_inputs -> self.num_stages, 1, res, res\n",
    "            alpha -> 1\n",
    "        \"\"\"\n",
    "        num_stages = self.curr_res_log2 - self.start_res_log2 +1\n",
    "\n",
    "        x = self.g_blocks[0]([g_input, w[:,0],noise_inputs[0]])\n",
    "\n",
    "        rgb = None\n",
    "        if num_stages==1:\n",
    "            rgb = self.to_rgb[0](x)\n",
    "        else:\n",
    "            for i in range(1,num_stages-1):\n",
    "                x = self.g_blocks[i]([x,w[:,i],noise_inputs[i]])\n",
    "            \n",
    "            old_rgb = self.to_rgb[num_stages-1](x)\n",
    "            old_rgb = self.up_sample(old_rgb)\n",
    "\n",
    "            i = num_stages -1\n",
    "            x = self.g_blocks[i]([x,w[:,i],noise_inputs[i]])\n",
    "\n",
    "            new_rgb = self.to_rgb[i](x)\n",
    "\n",
    "            rgb = fade_in(alpha[0],new_rgb, old_rgb)\n",
    "        \n",
    "        return rgb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, start_res_log2, target_res_log2) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.start_res_log2 = start_res_log2\n",
    "        self.target_res_log2 = target_res_log2\n",
    "        self.curr_res_log2 = self.start_res_log2\n",
    "\n",
    "        self.num_stages = target_res_log2 - start_res_log2 +1\n",
    "\n",
    "        self.filter_nums = {\n",
    "            0: 512,\n",
    "            1: 512,\n",
    "            2: 512,  # 4x4\n",
    "            3: 512,  # 8x8\n",
    "            4: 512,  # 16x16\n",
    "            5: 512,  # 32x32\n",
    "            6: 256,  # 64x64\n",
    "            7: 128,  # 128x128\n",
    "            8: 64,  # 256x256\n",
    "            9: 32,  # 512x512\n",
    "            10: 16,\n",
    "        }\n",
    "\n",
    "        self.d_blocks = []\n",
    "\n",
    "        self.from_rgb = []\n",
    "\n",
    "        for res_log2 in range(self.start_res_log2, self.target_res_log2 +1):\n",
    "            res = 2**res_log2\n",
    "\n",
    "            filter_num = self.filter_nums[res_log2]\n",
    "\n",
    "            from_rgb = nn.Sequential(\n",
    "                EqualisedConv2D(3,filter_num,1),\n",
    "                nn.LeakyReLU(0.2)\n",
    "            )\n",
    "\n",
    "            self.from_rgb.append(from_rgb)\n",
    "\n",
    "            d_block = DiscriminatorBlock(filter_num, self.filter_nums[res_log2-1],res,len(self.d_blocks)==0)\n",
    "            self.d_blocks.append(d_block)\n",
    "            \n",
    "        self.avg_pool = nn.AvgPool2d((2,2))\n",
    "        self.from_rgb = nn.ModuleList(self.from_rgb)\n",
    "        self.d_blocks = nn.ModuleList(self.d_blocks)\n",
    "    \n",
    "    def grow(self, res_log2):\n",
    "        self.curr_res_log2 = res_log2\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        input_image, alpha = inputs\n",
    "\n",
    "        res = 2 ** self.curr_res_log2 \n",
    "        idx = self.curr_res_log2 - self.start_res_log2\n",
    "\n",
    "        x = self.from_rgb[idx](input_image)\n",
    "        x = self.d_blocks[idx](x)\n",
    "\n",
    "        if idx >0 :\n",
    "            idx -=1\n",
    "            downsized_image = self.avg_pool(input_image)\n",
    "            y = self.from_rgb[idx](downsized_image)\n",
    "            x = fade_in(alpha[0],x,y)\n",
    "\n",
    "            for i in range(idx, -1, -1):\n",
    "                x = self.d_blocks[i](x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mapping(nn.Module):\n",
    "    def __init__(self, num_stages, input_shape = 512) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_stages = num_stages\n",
    "\n",
    "        self.layers = []\n",
    "        for _ in range(8):\n",
    "            self.layers.append(EqualisedLinear(input_shape, 512, 0.01))\n",
    "            self.layers.append(nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = pixel_norm(input)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return torch.tile(torch.unsqueeze(x,1),(1,self.num_stages,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phase(Enum):\n",
    "    TRANSITION = 1\n",
    "    STABLE = 2\n",
    "\n",
    "class OptimType(Enum):\n",
    "    ADAM = 1\n",
    "    \n",
    "class StyleGAN(nn.Module):\n",
    "    def __init__(self, z_dim = 512, target_res = 128, start_res = 4) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.z_dim = 512\n",
    "\n",
    "        self.target_res_log2 = log2(target_res)\n",
    "        self.start_res_log2 = log2(start_res)\n",
    "\n",
    "        self.curr_res_log2 = self.target_res_log2\n",
    "        self.num_stages = self.target_res_log2 - self.start_res_log2 +1\n",
    "\n",
    "        self.alpha = 1.0\n",
    "        self.train_step_counter = 0\n",
    "        \n",
    "\n",
    "        self.mapping = Mapping(self.num_stages, self.z_dim)\n",
    "        self.discriminator = Discriminator(self.start_res_log2, self.target_res_log2)\n",
    "        self.generator = Generator(self.start_res_log2,self.target_res_log2)\n",
    "\n",
    "        self.g_input_shape = self.generator.input_shape\n",
    "\n",
    "        self.phase = None\n",
    "\n",
    "        self.loss_weights = {\n",
    "            \"gradient_penalty\" : 10,\n",
    "            \"drift\" : 0.001\n",
    "        }\n",
    "    \n",
    "        \n",
    "    def grow_model(self, res):\n",
    "        res_log2 = log2(res)\n",
    "\n",
    "        self.generator.grow(res_log2)\n",
    "        self.discriminator.grow(res_log2)\n",
    "\n",
    "        self.curr_res_log2 = res_log2\n",
    "        print(f\"\\nModel resolution : {res}x{res}\")\n",
    "\n",
    "    def configure(self, steps_per_epoch, phase, res, d_optimizer : OptimType, g_optimizer: OptimType, *args, **kwargs):\n",
    "        self.loss_weights = kwargs.pop(\"loss_weights\",self.loss_weights)\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "        if res!= 2 ** self.curr_res_log2:\n",
    "            self.grow_model(res)\n",
    "            if d_optimizer == OptimType.ADAM:\n",
    "                self.d_optimizer = torch.optim.Adam(params = self.discriminator.parameters(), lr=1e-3, betas=(0.0,0.99),eps=1e-8)\n",
    "            if g_optimizer == OptimType.ADAM:\n",
    "                self.g_optimizer = torch.optim.Adam(params = self.generator.parameters(), lr=1e-3, betas=(0.0,0.99),eps=1e-8)\n",
    "        \n",
    "        self.train_step_counter = 0\n",
    "        self.phase = phase\n",
    "        self.d_loss_metric = torch.mean\n",
    "        self.g_loss_metric = torch.mean\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "    \n",
    "    def generate_noise(self,batch_size):\n",
    "        return [\n",
    "            torch.empty(batch_size,1, 2**res,2**res ).normal_()\n",
    "            for res in range(self.start_res_log2, self.target_res_log2+1)\n",
    "        ]\n",
    "    \n",
    "    def gradient_penalty(self, real_images : torch.Tensor, fake_images: torch.Tensor, alpha, batch_size):\n",
    "        epsilon = torch.empty(batch_size,1,1,1)\n",
    "\n",
    "        interpolated_images = epsilon * real_images + (1 - epsilon ) * fake_images\n",
    "        interpolated_images.requires_grad_(True)\n",
    "\n",
    "        mixed_scores = self.discriminator([interpolated_images,alpha])\n",
    "\n",
    "        loss_inter = wasserstein_loss(-torch.ones(batch_size), mixed_scores)\n",
    "\n",
    "        gradient = torch.autograd.grad(\n",
    "            inputs = interpolated_images,\n",
    "            outputs = loss_inter,\n",
    "            grad_outputs = torch.ones_like(loss_inter),\n",
    "            create_graph = True,\n",
    "            retain_graph = True \n",
    "        )[0]\n",
    "\n",
    "        gradient = gradient.view(gradient.shape[0],-1)\n",
    "        gradient_norm = gradient.norm(2, dim=1)\n",
    "        gradient_penalty = torch.mean((gradient_norm - 1)**2)\n",
    "        return gradient_penalty\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        self.g_optimizer.zero_grad()\n",
    "        self.train_step_counter +=1\n",
    "        \n",
    "        if self.phase == Phase.TRANSITION:\n",
    "            self.alpha = float(self.train_step_counter/ self.steps_per_epoch)\n",
    "        elif self.phase == Phase.STABLE:\n",
    "            self.alpha = 1.0\n",
    "        else:\n",
    "            raise NotImplementedError(\"Configure Model before training\")\n",
    "\n",
    "        alpha = torch.Tensor([self.alpha])\n",
    "        batch_size = real_images.shape[0]\n",
    "\n",
    "        real_labels = torch.ones(batch_size)\n",
    "        fake_labels = -torch.ones(batch_size)\n",
    "\n",
    "        z = torch.empty(batch_size, self.z_dim).normal_()\n",
    "        const_input = torch.ones(tuple([batch_size]+ list(self.g_input_shape)))\n",
    "        noise = self.generate_noise(batch_size)\n",
    "\n",
    "        w = self.mapping(z)\n",
    "        fake_images : torch.Tensor = self.generator([const_input, w, noise, alpha])\n",
    "\n",
    "        pred_fake = self.discriminator([fake_images, alpha])\n",
    "        \n",
    "        #### Generator Loss\n",
    "        g_loss = wasserstein_loss(real_images, pred_fake)\n",
    "\n",
    "        self.generator.zero_grad()\n",
    "        g_loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "\n",
    "        ### Discriminator Loss\n",
    "        pred_fake = self.discriminator([fake_images.detach(), alpha])\n",
    "        pred_real = self.discriminator([real_images, alpha])\n",
    "\n",
    "        loss_fake = wasserstein_loss(fake_labels, pred_fake)\n",
    "        loss_real = wasserstein_loss(real_labels, pred_real)\n",
    "\n",
    "        gradient_penalty = self.gradient_penalty(real_images, fake_images, alpha, batch_size)\n",
    "\n",
    "        all_pred = torch.concat([pred_fake, pred_real], dim=0)\n",
    "        drift_loss = self.loss_weights[\"drift\"] * torch.mean(all_pred ** 2)\n",
    "        \n",
    "        d_loss = loss_fake + loss_real + gradient_penalty + drift_loss\n",
    "\n",
    "        self.discriminator.zero_grad()\n",
    "        d_loss.backward()\n",
    "        self.d_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
